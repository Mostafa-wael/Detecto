{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 \n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import cross_validate, cross_val_predict, RandomizedSearchCV, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "import random\n",
    "from PIL import Image,ImageEnhance \n",
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score\n",
    "import codecs, json \n",
    "\n",
    "READ_FULL_DATA = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(img_file, sharpness_factor = 10, bordersize = 3):\n",
    "        im = Image.open(img_file)\n",
    "        \n",
    "        bright= ImageEnhance.Brightness(im)\n",
    "        if(np.average(np.array(im))<128):\n",
    "            im=bright.enhance(2.5)  \n",
    "              \n",
    "        enhancer = ImageEnhance.Sharpness(im)  \n",
    "        im_s_1 = enhancer.enhance(sharpness_factor)\n",
    "        # plt.imshow(im_s_1, cmap='gray')\n",
    "        \n",
    "        #(width, height) = (im.width , im.height * 2)\n",
    "        #im_s_1 = im_s_1.resize((width, height))\n",
    "        image = np.array(im_s_1)\n",
    "        image = cv2.copyMakeBorder(\n",
    "            image,\n",
    "            top=bordersize,\n",
    "            bottom=bordersize,\n",
    "            left=bordersize,\n",
    "            right=bordersize,\n",
    "            borderType=cv2.BORDER_CONSTANT,\n",
    "            value=[255,255,255]\n",
    "        )\n",
    "        orig_image = image.copy()\n",
    "        \n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        image = cv2.GaussianBlur(image,(3,3),0)\n",
    "        \n",
    "        (thresh, bw_image) = cv2.threshold(image, 128, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "        return bw_image, orig_image\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_contour_pixels(bw_image):\n",
    "        contours, _= cv2.findContours(\n",
    "            bw_image, cv2.RETR_TREE, \n",
    "            cv2.CHAIN_APPROX_NONE\n",
    "            ) \n",
    "        # contours = imutils.grab_contours(contours)\n",
    "        contours = sorted(contours, key=cv2.contourArea, reverse=True)[1:]\n",
    "        \n",
    "        img2 = bw_image.copy()[:,:,np.newaxis]\n",
    "        img2 = np.concatenate([img2, img2, img2], axis = 2)\n",
    "        return contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cold_features(contours,approx_poly_factor = 0.01):\n",
    "     \n",
    "        N_RHO_BINS = 7\n",
    "        N_ANGLE_BINS = 12\n",
    "        N_BINS = N_RHO_BINS * N_ANGLE_BINS\n",
    "        BIN_SIZE = 360 // N_ANGLE_BINS\n",
    "        R_INNER = 5.0\n",
    "        R_OUTER = 35.0\n",
    "        K_S = np.arange(3, 8)\n",
    "        \n",
    "        rho_bins_edges = np.log10(np.linspace(R_INNER, R_OUTER, N_RHO_BINS))\n",
    "        feature_vectors = np.zeros((len(K_S), N_BINS))\n",
    "        \n",
    "        # print([len(cnt) for cnt in contours])\n",
    "        for j, k in enumerate(K_S):\n",
    "            hist = np.zeros((N_RHO_BINS, N_ANGLE_BINS))\n",
    "            for cnt in contours:\n",
    "                epsilon = approx_poly_factor * cv2.arcLength(cnt,True)\n",
    "                cnt = cv2.approxPolyDP(cnt,epsilon,True)\n",
    "                n_pixels = len(cnt)\n",
    "                \n",
    "                point_1s = np.array([point[0] for point in cnt])\n",
    "                x1s, y1s = point_1s[:, 0], point_1s[:, 1]\n",
    "                point_2s = np.array([cnt[(i + k) % n_pixels][0] for i in range(n_pixels)])\n",
    "                x2s, y2s = point_2s[:, 0], point_2s[:, 1]\n",
    "                \n",
    "                thetas = np.degrees(np.arctan2(y2s - y1s, x2s - x1s) + np.pi)\n",
    "                rhos = np.sqrt((y2s - y1s) ** 2 + (x2s - x1s) ** 2)\n",
    "                rhos_log_space = np.log10(rhos)\n",
    "                \n",
    "                quantized_rhos = np.zeros(rhos.shape, dtype=int)\n",
    "                for i in range(N_RHO_BINS):\n",
    "                    quantized_rhos += (rhos_log_space < rho_bins_edges[i])\n",
    "                    \n",
    "                for i, r_bin in enumerate(quantized_rhos):\n",
    "                    theta_bin = int(thetas[i] // BIN_SIZE) % N_ANGLE_BINS\n",
    "                    hist[r_bin - 1, theta_bin] += 1\n",
    "                \n",
    "            normalised_hist = hist / hist.sum()\n",
    "            feature_vectors[j] = normalised_hist.flatten()\n",
    "            \n",
    "        return feature_vectors.flatten()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hinge_features(contours):\n",
    "\n",
    "        N_ANGLE_BINS = 40\n",
    "        BIN_SIZE = 360 // N_ANGLE_BINS\n",
    "        LEG_LENGTH = 25\n",
    "       \n",
    "        hist = np.zeros((N_ANGLE_BINS, N_ANGLE_BINS))\n",
    "            \n",
    "        # print([len(cnt) for cnt in contours])\n",
    "        for cnt in contours:\n",
    "            n_pixels = len(cnt)\n",
    "            if n_pixels <= LEG_LENGTH:\n",
    "                continue\n",
    "            \n",
    "            points = np.array([point[0] for point in cnt])\n",
    "            xs, ys = points[:, 0], points[:, 1]\n",
    "            point_1s = np.array([cnt[(i + LEG_LENGTH) % n_pixels][0] for i in range(n_pixels)])\n",
    "            point_2s = np.array([cnt[(i - LEG_LENGTH) % n_pixels][0] for i in range(n_pixels)])\n",
    "            x1s, y1s = point_1s[:, 0], point_1s[:, 1]\n",
    "            x2s, y2s = point_2s[:, 0], point_2s[:, 1]\n",
    "            \n",
    "            phi_1s = np.degrees(np.arctan2(y1s - ys, x1s - xs) + np.pi)\n",
    "            phi_2s = np.degrees(np.arctan2(y2s - ys, x2s - xs) + np.pi)\n",
    "            \n",
    "            indices = np.where(phi_2s > phi_1s)[0]\n",
    "            \n",
    "            for i in indices:\n",
    "                phi1 = int(phi_1s[i] // BIN_SIZE) % N_ANGLE_BINS\n",
    "                phi2 = int(phi_2s[i] // BIN_SIZE) % N_ANGLE_BINS\n",
    "                hist[phi1, phi2] += 1\n",
    "                \n",
    "        normalised_hist = hist / np.sum(hist)\n",
    "        feature_vector = normalised_hist[np.triu_indices_from(normalised_hist, k = 1)]\n",
    "        \n",
    "        return feature_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Females: 232 \tMales: 131 \n",
      "total: 363\n"
     ]
    }
   ],
   "source": [
    "# Read the data\n",
    "if READ_FULL_DATA:\n",
    "    img_contours = []\n",
    "\n",
    "    files_list = os.listdir('./data/Females')\n",
    "    for i in tqdm(range(len(files_list))):\n",
    "        img_path = f\"./data/Females/{files_list[i]}\"\n",
    "        bw_image, _ = preprocess_image(img_path)\n",
    "        contours = get_contour_pixels(bw_image)\n",
    "        img_contours.append(contours)\n",
    "\n",
    "    files_list = os.listdir('./data/Males')\n",
    "    for i in tqdm(range(132)):\n",
    "        img_path = f\"./data/Males/{files_list[i]}\"\n",
    "        bw_image, _ = preprocess_image(img_path)\n",
    "        contours = get_contour_pixels(bw_image)\n",
    "        img_contours.append(contours)\n",
    "\n",
    "\n",
    "males = [0] * len(os.listdir('./data/Females'))\n",
    "females = [1] * len(os.listdir('./data/Males'))\n",
    "y = males + females\n",
    "print(\"Females:\", len(females), \"\\tMales:\", len(males), \"\\ntotal:\", len(y))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the features\n",
    "if READ_FULL_DATA:\n",
    "    X_COLD = []\n",
    "    X_HINGE = []\n",
    "\n",
    "    for i in tqdm(range(len(img_contours))):\n",
    "        X_COLD.append(get_cold_features(img_contours[i]))\n",
    "        X_HINGE.append(get_hinge_features(img_contours[i]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# StandardScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "if READ_FULL_DATA:\n",
    "    scaler = StandardScaler()\n",
    "    X_COLD = scaler.fit_transform(X_COLD)\n",
    "    X_HINGE = scaler.fit_transform(X_HINGE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save features in json format\n",
    "if READ_FULL_DATA:\n",
    "\n",
    "    json.dump(X_COLD.tolist(), codecs.open('X_COLD.json', 'w', encoding='utf-8'), \n",
    "            separators=(',', ':'), \n",
    "            sort_keys=True, \n",
    "            indent=4) \n",
    "    json.dump(X_HINGE.tolist(), codecs.open('X_HINGE.json', 'w', encoding='utf-8'), \n",
    "            separators=(',', ':'), \n",
    "            sort_keys=True, \n",
    "            indent=4) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the features\n",
    "if not READ_FULL_DATA:\n",
    "\n",
    "    X_COLD = np.array(json.loads(codecs.open('X_COLD.json', 'r', encoding='utf-8').read()))\n",
    "    X_HINGE = np.array(json.loads(codecs.open('X_HINGE.json', 'r', encoding='utf-8').read()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COLD Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9406110401358289"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calc the PCA for COLD features\n",
    "pca_COLD = PCA(n_components=50)\n",
    "X_train_COLD_PCA = pca_COLD.fit_transform(X_COLD)\n",
    "np.sum(pca_COLD.explained_variance_ratio_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train on the COLD features\n",
    "temp = list(zip(X_train_COLD_PCA, y))\n",
    "random.shuffle(temp)\n",
    "res1, res2 = zip(*temp)\n",
    "\n",
    "scoring = {'accuracy' : make_scorer(accuracy_score), \n",
    "           'precision' : make_scorer(precision_score),\n",
    "           'recall' : make_scorer(recall_score), \n",
    "           'f1_score' : make_scorer(f1_score)}\n",
    "\n",
    "clfR = RandomForestClassifier(n_estimators=10000) \n",
    "scores = cross_val_score(clfR, res1, res2, cv=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.749056603773585\n"
     ]
    }
   ],
   "source": [
    "# print(np.average(scores['test_accuracy']))\n",
    "# print(np.average(scores['test_f1_score']))\n",
    "print(np.average(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HINGE Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9121056440996939"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calc the PCA for HINGE features\n",
    "pca_HINGE = PCA(n_components=100)\n",
    "X_train_HINGE_PCA = pca_HINGE.fit_transform(X_HINGE)\n",
    "np.sum(pca_HINGE.explained_variance_ratio_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train on the HINGE features\n",
    "temp = list(zip(X_train_HINGE_PCA, y))\n",
    "random.shuffle(temp)\n",
    "res1, res2 = zip(*temp)\n",
    "\n",
    "scoring = {'accuracy' : make_scorer(accuracy_score), \n",
    "           'precision' : make_scorer(precision_score),\n",
    "           'recall' : make_scorer(recall_score), \n",
    "           'f1_score' : make_scorer(f1_score)}\n",
    "\n",
    "clfR = RandomForestClassifier(n_estimators=10000) \n",
    "scores = cross_validate(clfR, res1, res2, cv=5, scoring=scoring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7907837445573295\n",
      "0.7918249157427849\n"
     ]
    }
   ],
   "source": [
    "print(np.average(scores['test_accuracy']))\n",
    "print(np.average(scores['test_f1_score']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COLD & HINGE Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train on the COLD and HINGE features\n",
    "X_train_PCA = np.concatenate([X_COLD, X_HINGE], axis=1)\n",
    "temp = list(zip(X_train_PCA, y))\n",
    "random.shuffle(temp)\n",
    "res1, res2 = zip(*temp)\n",
    "\n",
    "clfR = RandomForestClassifier(n_estimators=10000) \n",
    "scores = cross_val_score(clfR, res1, res2, cv=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7414368650217706\n"
     ]
    }
   ],
   "source": [
    "# print(np.average(scores['test_accuracy']))\n",
    "# print(np.average(scores['test_f1_score']))\n",
    "print(np.average(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
